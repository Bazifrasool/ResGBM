{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e6841b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py \n",
    "import numpy as np\n",
    "fs  = h5py.File(\"FeatureMatrix_trainedmodel.hdf5\",\"r\")\n",
    "ds = fs[\"featuresmatrix\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "783d2f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7872, 2)\n",
      "(7872, 2048)\n"
     ]
    }
   ],
   "source": [
    "ds_arr = ds[:]\n",
    "ytarget=np.load(\"YpredforClassesWname.npy\")\n",
    "print(ytarget.shape)\n",
    "print(ds_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7641cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = np.concatenate((ds_arr,ytarget[:,1].reshape(-1,1)),axis=1).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1223e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(total[:,:-1], total[:,-1], test_size = 0.1, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8e7f2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.          60.105076     0.         ...   1.6668444    0.55340534\n",
      "    0.        ]\n",
      " [  0.          48.090134     0.         ...   0.           0.5371359\n",
      "    0.        ]\n",
      " [  0.          54.250893     0.         ...   0.           0.6163479\n",
      "    0.        ]\n",
      " ...\n",
      " [  0.          74.922195     0.         ...  10.39827      0.47490913\n",
      "    0.        ]\n",
      " [  0.         109.463135     0.         ...   0.           1.6297406\n",
      "    0.        ]\n",
      " [  0.          81.434784     0.         ...   0.           0.47103834\n",
      "    0.        ]]\n",
      "LightGBM Model accuracy score: 0.8058\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "import lightgbm as lgb\n",
    "clf = lgb.LGBMClassifier(n_estimators=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "# predict the results\n",
    "y_pred=clf.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy=accuracy_score(y_pred, y_test)\n",
    "print('LightGBM Model accuracy score: {0:0.4f}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55a8597f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      " [[231  12  27]\n",
      " [ 35 196  26]\n",
      " [ 35  18 208]]\n",
      "\n",
      "True Positives(TP) =  231\n",
      "\n",
      "True Negatives(TN) =  196\n",
      "\n",
      "False Positives(FP) =  12\n",
      "\n",
      "False Negatives(FN) =  35\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion matrix\\n\\n', cm)\n",
    "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
    "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
    "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
    "print('\\nFalse Negatives(FN) = ', cm[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f175f614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.86      0.81       270\n",
      "         1.0       0.87      0.76      0.81       257\n",
      "         2.0       0.80      0.80      0.80       261\n",
      "\n",
      "    accuracy                           0.81       788\n",
      "   macro avg       0.81      0.81      0.81       788\n",
      "weighted avg       0.81      0.81      0.81       788\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da0b0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
